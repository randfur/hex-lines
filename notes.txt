# 2024-09-25
- Found out it doesn't work on mobile Chrome.
  - Multisample count is too high.
  - Found out how to query max multisamples.
  - Works now.

# 2024-09-04
- NaN is actually a constant you can use in JS, replaced the use of undefined.
- Started implementing the renderbuffer + texture rewrite.
  - Renamed FrameBuffer to Layer.
  - Got it kind of working.
    - Render buffer multi sampling works.
    - Stars aren't rendering but shape and circles are.
    - Stars are Group(Line) while shape and cirles are Group(Group(Line)).
    - Surprising that the more simpler one is working.
    - Perhaps an issue with blitting the renderbuffer onto the texture.
    - Turns out the stars do draw but they get clobbered by the shape drawing.
    - Subsequent circle drawings don't clobber the shape drawings.
  - Fixed the bugs.
    - Wasn't blit transferring the buffer as a layer was converted between texture and renderbuffer as its target.
  - Picking sample count.
    - 3 is acceptable.
    - 6 is great.
    - Going with 4 because that's what WebGPU accepts.
      - https://webgpufundamentals.org/webgpu/lessons/webgpu-multisampling.html
      - Looks like WebGPU supports multisampling on textures, this eliminates the need to blit between the two and could be a significant performance boost.
      - Will maybe one day implement a WebGPU graphics backend that kicks in when it's available.
- Hex lines 2D is done?
  - No, should really add sub section rendering to avoid copying the entire texture over for every layer.
  - Functionality wise, probably yes.
  - Maybe add a colour transform matrix for drawings.
- basic-2d-next demo.
  - Added more circles.
  - Nested them into each other as groups with opacity to demonstrate nested opacity.

# 2024-09-02
- Fixed angle bug where 0 angle disabled the dot.
  - Using isnan(fromSize) to determine whether a hex should be drawn.
  - Turns out setting undefined in float32 sets it to NaN.
    - Number(undefined) is NaN.
- Rotated angle 0 so the hexagon was horizontal.
- Made angle optional and default to 0 for dots.
- Added spinning transparent circles to basic-2d-next example.

# 2024-08-23
- Goal: Get antialiasing.
  - Need renderbuffer to do so.
  - Makes the FrameBuffer stack much more complex.
  - For each FrameBuffer level:
    - Render into renderbuffer with antialiasing.
    - Copy into texture ready for compositing into parent FrameBuffer.
  - Optimisation:
    - Is this already optimal given GroupDrawings don't create a nested level if they don't require compositing?
    - Need to assess specific examples.
    - Value of only copying sub regions becomes more valuable now given there's two buffer copies happening.
  - Need to juggle within the FrameBuffer whether the renderbuffer has the data or the texture does.
    - LineDrawing:
      - Target existing content in renderbuffer:
        - Render to renderbuffer.
      - Target existing content in texture:
        - Copy texture to renderbuffer.
        - Render to renderbuffer.
    - GroupDrawing compositing:
      - Target existing context in renderbuffer:
        - Nested content in renderbuffer:
          - Copy nested content to nested texture.
          - Composite nested texture to target renderbuffer.
        - Nested content in texture:
          - Composite nested texture to target renderbuffer.
      - Target existing context in texture:
        - Nested content in renderbuffer:
          - Copy nested content to nested texture.
          - Composite nested texture to target texture.
        - Nested content in texture:
          - Composite nested texture to target texture.
    - Kinda messy, some structure to it but not sure how nicely it will generalise across all flows.
    - Possible general flow:
      - LineDrawing:
        - Ensure target content is in renderbuffer.
        - Render to target renderbuffer.
      - GroupDrawing compositing:
        - Ensure nested content is in texture.
        - Render to target (whichever buffer is active).
    - FrameBuffer API:
      - activateRenderbuffer()
      - activateTexture()
      - getActiveFramebuffer()

# 2024-08-04
- Updated addRawPointsData() to accept RGB as a u24.
  - Setting on data view directly.
  - Turns out need to not use kLittleEndian for the u32 since it's read as individual u8s in sequence on the GPU.
- Would like to get antialiasing of the lines back, needs use of render buffers and additional blit passes.
  - Can probably add a render buffer to each FrameBuffer for line drawings to use and group drawings that flatten pixelSize or opacity can ensure the render buffer is blitted down.

# 2024-08-03
- Fix bug in addRawPointsData().
  - Never called it before, not surprised it had bugs.
  - Typo in variable name.
  - Did not account for += 6 when getting the index of which point was being set.

# 2024-07-27
- Put basic-2d-next demo stars into a circle.

# 2024-07-16
- Transform.
  - Plumbed through from API to program.
  - Converted to row major with a transpose in the shader.
  - Added multiply util function.
  - Transform matricies appear to compose correctly.

# 2024-07-13
- Should line drawings have transform?
  - Start with just on group drawings for now.
  - Added transform matrix to line drawing program.
    - Using a hard coded rotation based on time for now, need to do transfrom stacking.
    - Confirmed that the uniform matrix expects the numbers in column major order.
    - Will probably do a transpose in the shader to avoid having column major matrices CPU side.

# 2024-07-03
- Fixed alpha blending between textures, was multiplying the original alpha in when it was already premultiplied in causing it to double and darken all the colours.

# 2024-07-01
- Blending:
  - Experimented in experiments/2024/image-compositing.
  - Had conversations with Claude-3.5 about premultiplied colour blending.
    - https://claude.ai/chat/7e6e4511-f3cf-4076-82bb-dfaae231ad3b
  - Added premultiplication to the source colour.
  - Seems to work! Needs more extensive testing.

# 2024-06-03
- Added pixelation.
  - Created a PoolMap.
    - A map of Pools keyed by a key.
  - Doesn't come with nice anti-aliasing.
    - Seems to require using renderbuffers to enable multisampling.
    - Not compatible with rendering back to the canvas with blending.
    - Seems like you can blit the renderbuffer into a texture.
      - https://stackoverflow.com/a/55976760/866521
    - A bit unfortunate but only more expensive by a blit which should be cheap.
- Should be pretty simple to add opacity on top of pixelation.
  - Got it working, quite simple to add, just a uniform.
  - Having trouble with opacity in a nested layer.
  - Seems to get too much alpha, might be multiplying too much or something.
  - Might need to do a manual calculation to verify blendFuncSeparate is working as expected.

# 2024-06-01
- Got a basic render working!
  - And with half as many vertex points as before to produce the same number of triangles.
- Next:
  - Add pixelation.
  - Add transformations.
  - Add opacity.
  - Add nested group drawings.
    - Add render buffer management.

# 2024-05-31
- Implementing 2D hex-lines.
- Naming:
  - Not sure whether to stick "2d" in the name of every class.
  - Will do without 2d name for now.
  - See how it is when there's a 3D implementation.
  - Don't really expect the two to be mixed.
- Reimplementing line buffer.
  - Omitting alpha in colour.
  - Not encoding as u32 this time, hoping to read it out as vec3.
  - Slightly different data entry API.
    - Dedicated dot surface, user doesn't deal with nulls.
- Reimplementing shaders.
  - Reconsidering hexagon triangles.
  - Found a way to use triangle list.
  - Needs degenerate triangle to split up the line segments.
    - Just repeat last point to make 0 area triangle.
  - Will find out if it works.
  - Implemented first pass of vertex shader, needs more stuff hooked up to find out if it works.
  - Had some problems with passing the u8s to a vec3 in the shader, turns out it just simply because the vertex buffer hadn't been uploaded to the GPU.

# 2024-05-29
- 3D prototype:
  - Implemented in: https://github.com/randfur/experiments/blob/main/2024/translucent-triangle/
  - Does opacity and pixelation with depth testing.
  - Performance probably won't scale too well due to needing texture passes with each layer.
  - Still some questions around how the depth testing is going to work with a tree of rendering.
    - Needs implementation.
  - Leaving 3D for now to do 2D.
    - 2D much simpler and is main goal at the moment.
      - Animation editor.
- Interfaces:
  - Split 2D and 3D interfaces up.
  - 2D/3D hex line shader can still be shared.
  - 2d and 3d directories for hex-lines-2d.js and hex-lines-3d.js.
- Triangulation:
  - Would be nice to have polygon rendering to fill in sections.
  - Can render it with an optional gradient.
  - Not sure how to turn a sequence of points into triangles that make up the polygon.
  - Will have to be a separate prototype.
2D:
  - Classes:
    - Context.
    - Group drawing.
    - Image drawing.
    - Hex lines buffer.

# 2024-05-06
- Considering 3D:
  - How to handle opacity/pixelation with depth buffers.
  - Could continue to do depth buffering with broken opacity support across layers.
  - Up to the user to render back to front to have correct opacity.
  - Would be neat if existing pixel had transparency with close depth and blend it over drawn pixel with further away depth.
    - Needs access to the existing pixel for that, not the case.
    - Sounds like a texture can be an input and a render target at the same time.
    - Not ideal performance wise though, reading and writing to the texture needs synchronisation overhead.
    - Better to render to a separate texture target.
    - Should try in a test bed.
  - Alternate 3D opacity idea:
    - Render all opaque drawings first to build depth buffer.
    - Render all transparent layers separately and blit with depth testing but no writing.
    - Ordering might be broken but should be mostly fine.
    - Rendering the transparent layers will be a recursive operation.
  - Ordering:
    - Each drawing can provide an origin (which will be transformed by its transform hierarchy).
    - Each draw group can specify whether to depth sort the origins of its children.
    - Depth sorting of transparent things can happen within a draw group.

# 2024-04-28
- How to translate transparent-pixelation-rendering into WebGL.
  - RenderBuffers are efficient for offscreen rendering, more efficient than textures supposedly.
  - Can blit render buffers into other render buffers.
    - Can do nearest neighbour resizing and blending.
    - Can apply opacity using the blend colour constant which can be referenced in blend func factors.
  - drawImage():
    - Do the regular rendering.
  - drawGroup():
    - if opacity or greater pixelation:
      - Add to render buffer stack.
      - Draw children into it.
      - Set up opacity in blending.
      - Blit top of stack to the one below it.
      - Pop stack.
    - else:
      - Draw children into current stack.
- Depth information.
  - Render frames can hold depth information.
  - Can't keep depth testing when blitting one render buffer onto another.
  - Need to use textures instead and do the depth test manually in the shader.
  - Not sure what 3D support is going to look like with this group drawing scheme and how it interacts with opacity.
    - Possibly any group with opacity ceases to have depth testing.
    - But what will get written into the depth buffer when an opaque group has been drawn?
    - Maybe try to preserve depth testing and copying over.

# 2024-04-08
- Got proof of concept in [transparent-pixelation-rendering](https://github.com/randfur/experiments/tree/main/2024/transparent-pixelation-rendering) experiment.
  - Changed pixelation to be at a GroupDrawing level rather than a HexLinesDrawing level.
  - Optimisation now much simpler than previously expected.

# 2024-03-10
- Efficient alpha and pixelSize drawing algorithm:
  - Difficult to perform good reuse to optimise the common cases to avoid redundant texture buffers.
  - If alpha and pixelSize is always 1 then should be rendering directly into canvas.
    - This might be a bit too complex to be worth it.
    - Going to go with always having a pixelation pass when rendering to the canvas.
  - Possible buffer data structure: {
      mergeTarget: {
        buffer,
      },
      pixelationTarget: {
        buffer,
        pixelSize,
      },
    }
  - Merge target is always pixel size 1.
    - Alpha transparency forces pixelisation.
    - Could be more optimal but probably fine.
    - Having pixelSize on the merge target is very complex to manage.
  - Initial draw values: {
      mergeTarget: {
        buffer: canvas,
      },
      pixelationTarget: {
        buffer: null,
        pixelSize: null,
      },
    };
    - GroupDrawing:
      - Alpha < 1:
        - Flush pixelation target to outer merge target.
        - Start inner merge target as null.
        - Nested draw values: {
            mergeTarget: {
              buffer: null,
            },
            pixelationTarget,
          };
        - If outer merge target:
          - Flush inner merge target || pixelation target to outer merge target.
        - Else:
          - Set outer merge target to inner merge target.
      - Alpha === 1:
        - Pass draw values through unchanged.
    - HexLinesDrawing:
      - If pixelation target pixel size doesn't match hex lines drawing pixel size:
        - Flush pixelation target to merge target, creating one if need be.
      - Draw into pixelation target.

# 2024-03-09
- Drawing layers:
  - New drawing object.
  - Renders to an intermediate buffer.
  - Renders that buffer onto the main canvas with a given pixelation and transparency.
  - Remove the A part of RGBA in colour.
  - Pixelation:
    - Intermediate buffer can probably be the same size as the screen.
    - May need to pick where to render in the intermediate buffer based on screen translation.
    - Probably just pretend the intermediate buffer is smaller based on pixelation.
    - Allowing mixed pixelation will be good for certain depth effects as well as mixing in more high resolution text.
  - Need to consider how the animation format will work with draw layers now.
  - Drawing layers take hex lines to draw.
    - Hex lines can be shared across layers and drawn multiple times.
      - They represent a buffer contents.
    - Drawing layers need to redraw their hex lines each frame? Not sure.
- Rethinking API:
  - A draw item is either:
    - A hexLines with pixelSize and transform.
    - An opacity group of draw items with a given alpha.
  - Opacity can nest but pixelSize and transform cannot.
    - Maybe let transforms nest for convenience?
  - API:
    - interface HexLinesContext {
        ...
        createHexLinesBuffer(hexPoints);
        draw(drawing: GroupDrawing | HexLinesDrawing);
      }
    - class HexLineDrawing {
        constructor(hexLinesBuffer, pixelSize?, transform?);
      }
    - class GroupDrawing {
        constructor(drawings: Array<GroupDrawing | HexLineDrawing>, alpha?, transform?);
      }
- Drawing algorithm:
  - Goal:
    - If opacity and differing pixelSizes aren't used then it should have no extra intermediate texture costs.
  - Inefficient basic approach:
    function draw(drawing, target=null, outerTransform=null) {
      if (drawing instanceof GroupDrawing) {
        drawGroup(drawing, target, outerTransform);
      } else {
        drawHexLines(drawing, target, outerTransform);
      }
    }

    function drawGroup(groupDrawing, targetFrameBuffer, outerTransform) {
      const intermediateFrameBuffer = createFrameBuffer();
      const transform = multiply(outerTransform, groupDrawing.transform);
      for (const drawing of groupDrawing.drawings) {
        draw(drawing, intermediateFrameBuffer, transform);
      }
      blitTextureWithAlpha(
        intermediateFrameBuffer.texture,
        targetFrameBuffer,
        groupDrawing.alpha,
      );
    }

    function drawHexLines(hexLinesDrawing, targetFrameBuffer, outerTransform) {
      const intermediateFrameBuffer = createFrameBuffer();
      const transform = multiply(outerTransform, hexLinesDrawing.transform);
      // Draw hexLines into intermediateFrameBuffer using transform.
      blitTextureWithPixelSize(
        intermediateFrameBuffer.texture,
        targetFrameBuffer,
        hexLinesDrawing.pixelSize,
      );
    }
  - Can probably store the pixelSize intended for the intermediate frame buffers and reuse them if they match.
  - GroupDrawings with alpha 1 can render directly onto the target frame buffer.
  - Optimised approach:
    - Ideally, if the pixelSize is the same for every HexLinesDrawing, renders everything to that smaller canvas size for everything including the opacity layers.
    - As soon as a different pixelSize is seen it'll have to upgrade to pixelSize 1 to combine them.
    - Combining only happens in a GroupDrawing so most of the logic would probably live in there.
    - Attempt (ignoring transform):
      function draw(drawing) {
        const pixelationBuffer = {
          lastPixelSize: null,
          buffer: createBuffer(),
        };
        const alphaBuffer = drawDrawing(drawing, /*alphaBuffer=*/null, pixelationBuffer);
        drawIntoCanvas(alphaBuffer, pixelationBuffer);
      }

      function drawDrawing(drawing, alphaBuffer, pixelationBuffer) {
        if (drawing instanceof GroupDrawing) {
          return drawGroup(drawing, alphaBuffer, pixelationBuffer);
        }
        return drawHexLines(drawing, alphaBuffer, pixelationBuffer);
      }

      function drawGroup(groupDrawing, outerAlphaBuffer, pixelationBuffer) {
        if (groupDrawing.alpha < 1) {
          outerAlphaBuffer = flushPixelationBuffer(pixelationBuffer, outerAlphaBuffer);
        }
        const innerAlphaBuffer = groupDrawing.alpha < 1 ? null : outerAlphaBuffer;
        for (const drawing of groupDrawing.drawings) {
          innerAlphaBuffer = draw(drawing, innerAlphaBuffer, pixelationBuffer);
        }
        if (groupDrawing.alpha < 1) {
          outerAlphaBuffer = flushOpacity(
            innerAlphaBuffer,
            pixelationBuffer,
            outerAlphaBuffer,
          );
        }
        return outerAlphaBuffer;
      }

      function drawHexLines(hexLinesDrawing, alphaBuffer, pixelationBuffer) {
      }
      // WIP unfinished.

# 2023-11-19
- Exposed transform and cameraTransform matrices on HexLinesContext.
  - Matrices are now set on every draw call.
  - Moved multiplication to the left of the position.
  - Still working out whether this works as expected or not.
  - Should rename them to worldTransform and modelTransform.
    - Done.
    - Renamed them to just transformMatrix and put them on the context and hex lines respectively.
- Fixed overflow: 0 bug.
- Add touch-action: manipulation in the hopes it makes mouse/pointer move events work better on mobile.
  - Nope, maybe none works.

# 2023-11-17
- Halved the dot angle increment per instance, more pronounced now.

# 2023-11-16
- Redid addPointTwice() as addDot() which auto adds the null.
- Really gotta remove the alpha channel...

# 2023-10-27
- Default x, y, size, r, g, b to 0.
- Add addPointTwice().

# 2023-10-27
- Default alpha to 255.

# 2023-09-10
- Added setupFullPageContext() helper function to do the body CSS and canvas width height boiler plate.

# 2023-09-06
- Discovered why it was not working on mobile.
  - Mobile uses 16 bit floats and the default zMax value was set to 1000000.
  - The max f16 value is 65504.
  - https://en.wikipedia.org/wiki/Half-precision_floating-point_format
  - Updated default zMax to 65504 and all works now.
  - Was not an issue with the new w logic.
  - Also depth test is working now, likely due to using w properly.

# 2023-09-05
- 3D no longer working on mobile.
  - Black screen.
  - JS values seem to be computing correctly, likely a shader issue.
  - Tried adding depthTest option to disable it.
    - This was working backwards on my phone previously.
    - Disabling depth test did not fix it.
  - Need to bisect what happens in the shader that's causing the issue.

# 2023-09-03
- Perspective:
  - Researched how perspective matrices are calculated.
  - https://unspecified.wordpress.com/2012/06/21/calculating-the-gluperspective-matrix-and-other-opengl-matrix-maths/
  - Turns out z is non-linear.
  - Is of the form a + b / z after / w.
  - w is z / zDiv, can solve for a * z + b for (zNear, -1) and (zFar, 1).
  - Resulting equations have some similarity with article but not quite the same:
    - a = 2 / (zMax - zMin)
    - b = 1 - 2 / (zMax - zMin) * zMax
  - Used the computed value of z as a greyscale colour to debug the equation, looked cool.
  - Works! Work correctly with / w interpolation of depths, now long lines layer correctly.

# 2023-08-31
- Sharing code:
  - The 2D and 3D versions have a lot of overlap.
  - Can probably unify them into one with an is3d member.
  - Some concern over costs of if branches reading member fields in addPoint.
  - Probably not really a concern, should just try and see if there's any difference given bomber-hex-lines can serve as a benchmarking demo.
  - Done, doesn't seem too bad.
  - Left addPointFlat() as taking a z value, too complicated to not.
  - Updated bomber-hex-lines to use it, negligible difference.
- Perspective
  - Considering to make the perspective matrix transform the user's job rather than having zMin, zMax and zDiv.
  - Just work with the value of w in the shader after transformation.

# 2023-08-30
- Added flat version of adding points to attempt to avoid memory allocation from object destructuring.
- Moved methods onto hex line handle.
- Perspective interpolation.
  - Should be able to make use of w interpolation in the GPU.
  - The orientation should only be a 3x3 matrix, the outer 4x4 layer can be hand crafted to perform the divide by z.
    - Need to perform the z clamp into -1,1 and set w appropriately from 0 to far-near based on z.
  - The hemihex portions can operate on the post /w x y values and use *w to compensate.
- 2D broke at some point.
  - Been getting out of date.
  - Basic example is black screen, no errors.
  - Tried copy pasting the 3D into 2D and fixing it up, still black screen, no errors.
  - Might need to bisect to see when it broke.
  - Died in 635e7f9a70f0eb551fb8ae2440c347a61a0a64ad when moving methods into the handle.
    - This affected one of the utils.
  - Found it:
    - Misnamed variable in basic-2d, don't know why I didn't see an error.
    - Forgot to update transform matrix (which still hasn't seen usage) to 3x3 instead of 4x4.
  - Works again.
- Dots:
  - You can draw them with different sizes and colours for each hemihex half.

# 2023-08-29
- Updated 3D handle to hold the ArrayBuffer and provide methods for writing points into it.
  - Will recycle the ArrayBuffer between clears and resize it as needed.
  - Still need to write this for the 2D context, just want to get this working for bomber-hex-lines to use.

# 2023-08-27
- 3D
  - Vertex shader needs to do a few things for 3D
    - Apply camera transform.
    - Clip zNear.
    - Apply zDiv to get 2D points.
    - Invoke regular 2D flow.
  - Will create a struct to hold the data as it goes through this pipeline of transforms, easier to write functions for each stage.
  - Moved shader into vertex-shader.js and created a builder function to generate the shader for 2D and 3D.
    - `` ${} string interpolation being used as preprocessing.
    - Basically #ifdef.
  - A bit unfortunate these transformations need to happen per vertex rather than per point but should be fine, still orders of magnitude than doing it linearly on the CPU.
    - This could probably be done better with WebGPU with effectively a geometry shader to generate all the hex line vertices from one 3D transform application.
  - Using left handed co-ordinate system.
    - Z positive goes into screen, X goes right, Y goes up.
- Wrote 3D version.
  - Works!
  - Shader covers both 2D and 3D using preprocessor style ${}.
  - 3D feeds into 2D code path to draw to screen.
  - Updated JS side to work with new attributes and uniforms.
  - Updated 3D example to use 2D example plus various z values.
    - Added camera rotation via hand crafted matrix.
  - Added depth test.
    - Mostly working but lines intersecting don't layer correctly, maybe something to do with having applied perspective myself?
    - Yeah the z values wouldn't be linear along the line with perspective...
    - May have to actually use GL w perspective.
      - This is tricky because the hex shape needs to be aligned with the screen.
      - Maybe the w can be faked and the x,y values pre-multiplied by w.
      - Gonna try that for a while first.
      - Updated zDiv to be used in w only but layering still wrong.
      - Also lines go funny when they're going towards the camera.
        - Hex angle calculation probably wrong now, needs to be post zDiv.
    - Reverting back to not using w to fix glitch on lines aiming at camera.
    - Should probably figure out billboarding instead.

# 2023-08-26
- 2D/3D
  - Renaming existing code to be 2D.
  - Files are xyz-2d.js, functions are xyz2d().
  - Added utils.js file for sharing stuff.
    - Should probably share a lot of the shader code.
    - 3D shader can probably build on top of the 2D shader.
    - Can turn the 2D stuff into a helper function they both call into with start and end positions.
  - 3D rendering.
    - Will not use actual 3D rendering for now (as in setting w to non-one values).
    - Will do z div in shader just like the bomber experiment does.
    - May change this later, will probably be hard to interop with other 3D rendering that uses traditional perspective matrix transforms.
    - Will see where it becomes a problem and fix then.
    - Need to apply non-perspective camera transforms separate to perspective transforms to draw the line thickness, can't have the HexVertex offsets getting transformed by the camera orientation, they must be in the final xy plane.
  - How to deal with min and max Z?
    - Clip co-ordinates need to be between -1 and 1.
    - Caller will need to specify camera transform, minZ, maxZ and zDiv.
    - These should be able to turn the 3D points into 2D points to feed into the 2D code.
    - Will need to do near and far clipping manually.
- Origin
  - Want to move 0,0 to be in the centre of the canvas instead of top left.
  - Not totally sure it's a good idea to break from convention but my use cases seem like they'll benefit from it.
  - While I'm at it I may as well have y flipped to match OpenGL.
  - All these quirks of rendering will need good documentation.
    - 0,0 in centre.
    - x goes right, y goes up.
    - Bounds are -width/2,-height/2 to width/2,height/2.
    - Perspective controlled by a zDiv parameter.
    - Camera transform must not have perspective in it.
    - All lines need to be terminated by a size 0 hex point including the last one.
    - Drawing a dot requires two hex points in the same location.
  - Done.
- Dots
  - Considering having the dot orientation depend on gl_instanceID.
  - Give it a bit of randomness.
  - Can just cos,sin some function on instance ID.
  - Done.

# 2023-08-25
- Fixed Firefox by using a DataView to write the colour as a u32 directly instead of having it pass through f32 format.
  - Added setHexPoint() and setHexPoints() helper functions to operate on a DataView.
  - Created a point object format to pass in to these or pass in null for empty points.
    - Concerned about performance impact of this object, will probably add a non-object version later.
  - Added hexPointsToArrayBuffer() as convenience helper.
- 2D/3D support
  - There should probably be 2D and 3D versions of this library; hex-lines-2d and hex-lines-3d.
  - For 3D uses like bomber-hex-lines it isn't efficient to do depth sorting and camera transforms on the CPU
  - According to the performance tab in DevTools most of the time is spent on depth sorting.
  - With depth culling depth sorting can be eliminated entirely (at the loss of alpha channel ease of use).

# 2023-08-24
- Added colour support.
  - Using GL blend modes to support alpha.
  - this.gl.blendFunc(this.gl.SRC_ALPHA, this.gl.ONE_MINUS_SRC_ALPHA) does an interpolation from destination pixel to source pixel using the source's alpha.
  - Exposed rgbaToFloat32() helper function.
    - Weirdly found that object parameter destructuring had better performance than flat parameters??
      - https://jsperf.app/qikobi
      - Need to stress test this perf test but using it for now.
- Reduced vertex count.
  - Only half a hex is required per side now that they're rotated to be aligned with the line.
  - The term hemihex doesn't seem to exist on the internet.
- Changed the enabled logic to discard when either the start or end are size 0.
  - Means dots need two points to be rendered but that's fine.
  - The rendering of hemihexes makes this more okay since two points are needed anyway to make one hex.
- Used bivector logic instead of complex numbers to represent 2D rotation.
  - Was more arithmetic to come to the same result but doesn't use magic ii = -1, instead uses xx = 1 and xy = -yx.
- Added width and height support, input values are now in screen co-ordinates.
- Added pixelSize support, screen co-ordinates are still preserved.
  - Currently pixelSize is applied to the entire canvas, maybe this should be a per draw call decision making use of rendering to an intermediate texture to do the upscaling.
    - Performance cost of this is questionable compared to the current design since line drawing and texture drawing calls will be interleaved.
- Seems to work, what next?
  - Maybe refactor the bomber experiment to use this.
  - Hopefully get much higher performance.
  - See how this is to use.
  - It could probably use just one draw call.

# 2023-08-23
- Wondering about the number of draw calls since repeated shapes can't be instanced since instancing is already being used for the hex line itself.
  - Internet suggests 100s-1000 draw calls are okay.
  - Shouldn't be more than 100s of draw calls in the extreme case here. Should be alright.
- Created GitHub repo: https://github.com/randfur/hex-lines
- Recreated first hex from scratch with a couple of peeks at syntax from original experiment.
- Created hard coded hex line between two points.
- Writing from scratch has yielded a much simpler approach.
  - Down to three parameters per vertex.
  - Basis vectors of start hex, basis vectors of end hex and percentage between start and end.
  - Percentage fits nicely with lerp() (called mix() in GLSL).
- Remaining things:
  - Canvas width, height.
  - Scaling position and size by pixelSize.
  - Adding transform matrix uniform.
- On Firefox white and yellow appear as alpha 0.
  - Turns out those colours when put through the rgbaToFloat32() conversion come out as NaN.
  - Seems like Chrome is passing the exact NaN value through while Firefox is canonicalising it to some other value.
  - Maybe passing all the data via a Float32Array isn't the way to go and instead use a DataView to construct the buffer, this should avoid the issue entirely.

# 2023-08-22
- Library version of [hex-lines-webgl](https://github.com/randfur/experiments/tree/main/2023/hex-lines-webgl).
- Unsure how to manage GPU memory.
- Going to go with very basic approach, everything is a separate buffer and needs to be drawn separately.
- Possible optimisation later if needed would be to bundle multiple things into one buffer.
  - Can probably add that as an additional API.
  - Create a bundle of handles that cannot be mutated.
  - Would be useful for plain playback separate from editing.
- API surface:
  - class HexLinesContext {
      constructor(HTMLCanvasElement);
      add(bufferData): HexLinesHandle;
    }
  - class HexLinesHandle {
      update(bufferData);
      draw();
      remove();
    }
- Every buffer needs to have the vertex attributes bound separately.
  - Using vertex array objects to save on the switching.
